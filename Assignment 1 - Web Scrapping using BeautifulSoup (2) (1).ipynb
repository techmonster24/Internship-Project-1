{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Write a python program to display all the header tags from‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html =urlopen(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = bs.find_all(['h1','h2','h3','h4','h5','h6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('List all the header tags :', *titles, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request page source from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/chart/top/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the page source code\n",
    "page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap movie names\n",
    "scrapped_movies = soup.find_all('td',class_= 'titleColumn')\n",
    "scrapped_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse movie names\n",
    "movies = []\n",
    "for movie in scrapped_movies:\n",
    "    movie = movie.get_text().replace('\\n',\"\")\n",
    "    movie = movie.strip(\" \")\n",
    "    movies.append(movie)\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap ratings for movies\n",
    "scrapped_ratings = soup.find_all('td',class_='ratingColumn imdbRating')\n",
    "scrapped_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse ratings\n",
    "ratings = []\n",
    "for rating in scrapped_ratings:\n",
    "    rating = rating.get_text().replace('\\n',\"\")\n",
    "    ratings.append(rating)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap years of release of movies\n",
    "scrapped_years = soup.find_all('span',class_='secondaryInfo')\n",
    "scrapped_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse years\n",
    "years = []\n",
    "for year in scrapped_years:\n",
    "    year = year.get_text().replace('\\n',\"\")\n",
    "    years.append(year)\n",
    "\n",
    "years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the scrapped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['Movie Names'] = movies\n",
    "data['IMDM ratings'] = ratings\n",
    "data['Year of release'] = years\n",
    "data[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/india/top-rated-indian-movies/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the page source code\n",
    "page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap movie names\n",
    "Indian_movies = soup.find_all('td',class_= 'titleColumn')\n",
    "Indian_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse movie names\n",
    "movies = []\n",
    "for movie in Indian_movies:\n",
    "    movie = movie.get_text().replace('\\n',\"\")\n",
    "    movie = movie.strip(\" \")\n",
    "    movies.append(movie)\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap ratings for movies\n",
    "scrap_ratings = soup.find_all('td',class_='ratingColumn imdbRating')\n",
    "scrap_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse ratings\n",
    "ratings = []\n",
    "for rating in scrap_ratings:\n",
    "    rating = rating.get_text().replace('\\n',\"\")\n",
    "    ratings.append(rating)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap years of release of movies\n",
    "scrap_years = soup.find_all('span',class_='secondaryInfo')\n",
    "scrap_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse years\n",
    "years = []\n",
    "for year in scrap_years:\n",
    "    year = year.get_text().replace('\\n',\"\")\n",
    "    years.append(year)\n",
    "\n",
    "years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the Scrapped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Movie Names'] = movies\n",
    "df['IMDM ratings'] = ratings\n",
    "df['Year of release'] = years\n",
    "df[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                 ***Over***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "soup=BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract all teams\n",
    "teams=soup.find_all('span',class_='u-hide-phablet')\n",
    "Team1=[]\n",
    "Team2=[]\n",
    "for i in teams:\n",
    "    Team1.append(i.text.replace('\\n',''))\n",
    "Team2.append(Team1[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match1=[]\n",
    "topteammatch=soup.find('td',class_=\"rankings-block__banner--matches\")\n",
    "Match1.append(topteammatch.text)\n",
    "Match2=[]\n",
    "matches=soup.find_all('td',class_='table-body__cell u-center-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in matches:\n",
    "    Match2.append(i.text.replace('\\n',''))\n",
    "Match1.append(Match2[0:18:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Points1=[]\n",
    "topteampoints=soup.find('td',class_=\"rankings-block__banner--points\")\n",
    "Points1.append(topteampoints.text)\n",
    "Points2=[]\n",
    "points=soup.find_all('td',class_='table-body__cell u-center-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in points:\n",
    "    Points2.append(i.text.replace('\\n',''))\n",
    "Points1.append(Points2[1:19:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings1=[]\n",
    "topteamrating=soup.find('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "Ratings1.append(topteamrating.text.replace('\\n',''))\n",
    "ratings=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "Rating=[]\n",
    "for i in ratings:\n",
    "    Rating.append(i.text.replace('\\n',''))\n",
    "Ratings1.append(Rating[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------Top 10 Teams---------------')\n",
    "print('Teams',Team2)\n",
    "print('\\n')\n",
    "print('Matches',Match1)\n",
    "print('\\n')\n",
    "print('Points',Points1)\n",
    "print('\\n')\n",
    "print('Ratings',Ratings1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\")\n",
    "soup=BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player1=[]\n",
    "Playername1=soup.find('div',class_=\"rankings-block__banner--name\")\n",
    "Player1.append(Playername1.text)\n",
    "Player2=[]\n",
    "players=soup.find_all('td',class_='table-body__cell name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in players:\n",
    "    Player2.append(i.text.replace('\\n',''))\n",
    "\n",
    "Player1.append(Player2[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nation1=[]\n",
    "nationname1=soup.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "Nation1.append(nationname1.text.replace('\\n',''))\n",
    "Nation2=[]\n",
    "nationname2=soup.find_all('span',class_='table-body__logo-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nationname2:\n",
    "    Nation2.append(i.text.replace('\\n',''))\n",
    "    \n",
    "Nation1.append(Nation2[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating1=[]\n",
    "ratings1=soup.find('div',class_=\"rankings-block__banner--rating\")\n",
    "Rating1.append(ratings1.text)\n",
    "Rating2=[]\n",
    "ratings2=soup.find_all('td',class_='table-body__cell u-text-right rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ratings2:\n",
    "    Rating2.append(i.text.replace('\\n',''))\n",
    "    \n",
    "Rating1.append(Rating2[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------Top 10 Batsmen---------------')\n",
    "print('Players Name',Player1)\n",
    "print('\\n')\n",
    "print('Nationality',Nation1)\n",
    "print('\\n')\n",
    "print('Ratings',Rating1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bowler1=[]\n",
    "Bowlername1=soup.find('div',class_=\"rankings-block__banner--name-large\")\n",
    "Bowler1.append(Bowlername1.text)\n",
    "Bowler1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bowler2=[]\n",
    "Bowlers=soup.find_all('td',class_='table-body__cell rankings-table__name name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Bowlers:\n",
    "    Bowler2.append(i.text.replace('\\n',''))\n",
    "\n",
    "Bowler1.append(Bowler2[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nation1=[]\n",
    "nationname1=soup.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "Nation1.append(nationname1.text.replace('\\n',''))\n",
    "Nation2=[]\n",
    "nationname2=soup.find_all('span',class_='table-body__logo-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nationname2:\n",
    "    Nation2.append(i.text.replace('\\n',''))\n",
    "    \n",
    "Nation1.append(Nation2[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating1=[]\n",
    "ratings1=soup.find('div',class_=\"rankings-block__banner--rating\")\n",
    "Rating1.append(ratings1.text)\n",
    "Rating2=[]\n",
    "ratings2=soup.find_all('td',class_=\"table-body__cell rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ratings2:\n",
    "    Rating2.append(i.text.replace('\\n',''))\n",
    "    \n",
    "Rating1.append(Rating2[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------Top 10 Bowlers------------')\n",
    "print('Bowlers Name',Bowler1)\n",
    "print('\\n')\n",
    "print('Nationality',Nation1)\n",
    "print('\\n')\n",
    "print('Ratings',Rating1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i)Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "soup=BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams=soup.find_all('span',class_='u-hide-phablet')\n",
    "Team1=[]\n",
    "Team2=[]\n",
    "for i in teams:\n",
    "    Team1.append(i.text.replace('\\n',''))\n",
    "Team2.append(Team1[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match1=[]\n",
    "topteammatch=soup.find('td',class_=\"rankings-block__banner--matches\")\n",
    "Match1.append(topteammatch.text)\n",
    "Match2=[]\n",
    "matches=soup.find_all('td',class_='table-body__cell u-center-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in matches:\n",
    "    Match2.append(i.text.replace('\\n',''))\n",
    "Match1.append(Match2[0:18:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Points1=[]\n",
    "topteampoints=soup.find('td',class_=\"rankings-block__banner--points\")\n",
    "Points1.append(topteampoints.text)\n",
    "Points2=[]\n",
    "points=soup.find_all('td',class_='table-body__cell u-center-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in points:\n",
    "    Points2.append(i.text.replace('\\n',''))\n",
    "Points1.append(Points2[1:19:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings1=[]\n",
    "topteamrating=soup.find('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "Ratings1.append(topteamrating.text.replace('\\n',''))\n",
    "ratings=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "Rating=[]\n",
    "for i in ratings:\n",
    "    Rating.append(i.text.replace('\\n',''))\n",
    "Ratings1.append(Rating[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------Top 10 Teams---------------')\n",
    "print('Teams',Team2)\n",
    "print('\\n')\n",
    "print('Matches',Match1)\n",
    "print('\\n')\n",
    "print('Points',Points1)\n",
    "print('\\n')\n",
    "print('Ratings',Ratings1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\")\n",
    "soup=BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player1=[]\n",
    "Playername1=soup.find('div',class_=\"rankings-block__banner--name\")\n",
    "Player1.append(Playername1.text)\n",
    "Player2=[]\n",
    "players=soup.find_all('td',class_='table-body__cell name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in players:\n",
    "    Player2.append(i.text.replace('\\n',''))\n",
    "\n",
    "Player1.append(Player2[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nation1=[]\n",
    "nationname1=soup.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "Nation1.append(nationname1.text.replace('\\n',''))\n",
    "Nation2=[]\n",
    "nationname2=soup.find_all('span',class_='table-body__logo-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nationname2:\n",
    "    Nation2.append(i.text.replace('\\n',''))\n",
    "    \n",
    "Nation1.append(Nation2[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating1=[]\n",
    "ratings1=soup.find('div',class_=\"rankings-block__banner--rating\")\n",
    "Rating1.append(ratings1.text)\n",
    "Rating2=[]\n",
    "ratings2=soup.find_all('td',class_='table-body__cell u-text-right rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ratings2:\n",
    "    Rating2.append(i.text.replace('\\n',''))\n",
    "    \n",
    "Rating1.append(Rating2[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------Top 10 Batsmen---------------')\n",
    "print('Players Name',Player1)\n",
    "print('\\n')\n",
    "print('Nationality',Nation1)\n",
    "print('\\n')\n",
    "print('Ratings',Rating1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "soup=BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player1=[]\n",
    "Playername1=soup.find('div',class_=\"rankings-block__banner--name-large\")\n",
    "Player1.append(Playername1.text)\n",
    "Player2=[]\n",
    "players=soup.find_all('td',class_='table-body__cell name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in players:\n",
    "    Player2.append(i.text.replace('\\n',''))\n",
    "\n",
    "Player1.append(Player2[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nation1=[]\n",
    "nationname1=soup.find('span',class_=\"rankings-block__banner--nationality\")\n",
    "Nation1.append(nationname1.text.replace('\\n','')\n",
    "Nation2=[]\n",
    "nationname2=soup.find_all('span',class_='table-body__logo-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nationname2:\n",
    "    Nation2.append(i.text.replace('\\n',''))\n",
    "    \n",
    "Nation1.append(Nation2[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating1=[]\n",
    "ratings1=soup.find('div',class_=\"rankings-block__banner--rating\")\n",
    "Rating1.append(ratings1.text)\n",
    "Rating2=[]\n",
    "ratings2=soup.find_all('td',class_='table-body__cell rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ratings2:\n",
    "    Rating2.append(i.text.replace('\\n',''))\n",
    "    \n",
    "Rating1.append(Rating2[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------Top 10 All Rounders----------')\n",
    "print('Players Name',Player1)\n",
    "print('\\n')\n",
    "print('Nationality',Nation1)\n",
    "print('\\n')\n",
    "print('Ratings',Rating1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://www.amazon.in/s?k=under+20000&rh=n%3A1389401031&ref=nb_sb_noss\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Product=soup.find_all('span',class_=\"a-size-base a-color-base a-text-normal\")\n",
    "Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_names=[]\n",
    "for i in Product:\n",
    "    product_names.append(i.text.replace('\\n',''))\n",
    "product_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price=soup.find_all('span',class_=\"a-price-whole\")\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_prices=[]\n",
    "for i in Price:\n",
    "    product_prices.append(i.text.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_URL=[]\n",
    "for item in soup.find_all('img',class_=\"s-image\"):\n",
    "    Image_URL.append(item['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=soup.find_all('span',class_=\"a-icon-alt\")\n",
    "ratings=[]\n",
    "for i in rating:\n",
    "    ratings.append(i.text.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Write a python program to scrape house details from mentioned url. It should include house title, location, area, emi and price\n",
    "https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44N\n",
    "DUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8\n",
    "iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import ast\n",
    "import urllib.request\n",
    "from urllib.request import Request,urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = input(\"https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0%3D&propertyAge=0&radius=2.0%22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = Request(url,headers = {'user-Agent':'Mozilla/5,0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage = urlopen(req).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Soup = BeautifulSoup(webpage,'html.parser')\n",
    "html = Soup.prettify('utf-8')\n",
    "property_json ={}\n",
    "property_json['Detail_Broad']={}\n",
    "property_json['Address']={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tittle in soup.find all('tittle'):\n",
    "    property_json['tittle'] = tittle.text.strip()\n",
    "    \n",
    "    break\n",
    "    \n",
    "for meta in soup.find all('meta',attrs = {'name':'description'}):\n",
    "    property_json['Detail_short'] = meta['content'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for div in soup.find all('div',attrs={'class':'character-count-truncated'})\n",
    "    property_json['Detail_Broad']['Description']=div.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i.script) in enumerate (soup.find all('script',attrs = {'type':'application/id+json'}))\n",
    "    if i==0\n",
    "property_json['Detail_Broad']['House name']= json_data['House name']\n",
    "\n",
    "property_json['House_name']['Locality']= json_data['address']['addresslocality']\n",
    "\n",
    "property_json['House_name']['Area']= json_data['address']['areaaddress']\n",
    "\n",
    "property_json['House_name']['amount']= json_data['price']['areaprice']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.loads(script.text) \n",
    "property_json['price in $']= json_data['offers']['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_json['image']=json_data[image]\n",
    "     break\n",
    "    with open('data.json','w')as outfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(property_json,outfile,indent=4)\n",
    "    with open('output_file.html','wb')as file:\n",
    "    file.write(html) \n",
    "    \n",
    "    {\"Details_Broad\":{\"Total_house\":4},\n",
    "    \"House_name\":{\"area\":\"satara parisar\",\"Locality\":\"aurangabad\",\"amount\":\"3500\"},\n",
    "     \"House_name\":{\"area\":\"peshave nagar\",\"Locality\":\"aurangabad\",\"amount\":\"350\"},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Write a python program to scrape mentioned details from ‘https://www.dineout.co.in/delhi-restaurants/buffet-special’ :\n",
    "\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_name = []\n",
    "\n",
    "for i in soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    restaurant_name.append(i.text)\n",
    "restaurant_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine = []\n",
    "\n",
    "for i in soup.find_all(\"span\", class_=\"double-line-ellipsis\"):\n",
    "    cuisine.append(i.text)\n",
    "cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = []\n",
    "\n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []\n",
    "\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-rating rating-3\"):\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "for i in soup.find_all(\"div\", class_=\"restnt-rating rating-4\"):\n",
    "    ratings.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for i in soup.find_all('img',class_=\"no-img\"):\n",
    "    images.append(i['data-src'])\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.Write a python program to scrape weather details for last 24 hours from\n",
    "‘https://en.tutiempo.net/delhi.html?data=last-24- hours’ :\n",
    "i) Hour\n",
    "ii) Temperature\n",
    "iii) Wind\n",
    "iv) Weather condition\n",
    "v) Humidity\n",
    "vi) Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_data(query):\n",
    "     res=requests.get('https://en.tutiempo.net/delhi.html?data=last-24-'+query+'&APPID=****************************8&units=metric');\n",
    "         return res.json();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weather(result,city):\n",
    "    print(\"{}'s temperature: {}°C \".format(city,result['main']['temp']))\n",
    "    print(\"Wind speed: {} m/s\".format(result['wind']['speed']))\n",
    "    \n",
    "    print(\"Description: {}\".format(result['weather'][0]['description']))\n",
    "    print(\"Weather: {}\".format(result['weather'][0]['main']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    city=input('Enter the city:')\n",
    "     print()\n",
    "         try:\n",
    "        query='q='+city;\n",
    "        w_data=weather_data(query);\n",
    "        print_weather(w_data, city)\n",
    "        print()\n",
    "        \n",
    "        except:\n",
    "        print('City name not found...')\n",
    "if __name__=='__main__':\n",
    "     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Write a python program to scrape monument name, monument description, image url about top 10 monuments\n",
    "from 'https://www.puredestinations.co.uk/top-10-famous-monuments-to-visit-in-india/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as BeautifulSoup\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.puredestinations.co.uk/top-10-famous-monuments-to-visit-in-india/'\n",
    "response = requests.get(url)\n",
    "Soup = BeautifulSoup(response.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Monument = Soap.select('td.rankings-block__container .table-body__cell.name a ')\n",
    "link = [a.attrs.get('href') for a in Soap.select('td.rankings-block__container .table-body__cell.name a ') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating = [b.attrs.get('data-value')\n",
    "              for b in Soap.select('td.rankings-block__container .table .rating')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(10, len(Monument)):\n",
    "    Monument_string = Monument[index].get_text()\n",
    "    Monument_description = (' ' .join(Monument_string.split()).replace(' . ', ''))\n",
    "    Monument_name = Monument[len(str(index))+1:-7]\n",
    "    Image_url = htmldata = urlopen('https://www.puredestination.co.uk.png/')\n",
    "    soup = BeautifulSoup(htmldata, 'html.parser')\n",
    "    images = soup.find_all('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in images:\n",
    "    print(item['src'])\n",
    "    data = [\"Monument_name\":Monument_name],\n",
    "           [\"Monument_description\": Monument_description], \n",
    "           [\"Image_url\": Image_url[index]],\n",
    "           [\"Link\": link[index]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data,column,column1 =['Monument_name','Monument_description','Image_url',])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
